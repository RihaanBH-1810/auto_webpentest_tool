from ..crawler.main import main as run_crawler
from ..fuzzer.runscript import run_fuzzer
from multiprocessing import Process, Queue
import json

Process = []

def controller(url, config = {}):
    print(url)
    if config != {}:
        limit = config["limit"]
        recursion_depth = config["recursion_depth"]
        recursion = config["recursion"]
        run_crawler(url,limit=int(limit))
        if recursion:
             run_fuzzer(url,config["wordlist"],recursion=recursion ,depth=recursion_depth)
        run_fuzzer(url,config["wordlist"],recursion=config["recursion"],depth=config["depth"])
        

    else:
        run_crawler(url)

def run_seq_tests(file):
    with open(file, 'r') as f:
        urls = f.read()
    f.close()
    urls = json.loads(urls)
    

def generate_report():
    pass
